<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Differential Privacy 101</title>
  <meta name="description" content="The idea (and a little bit of math) behind differential privacy, or, questions people ask at parties.  [Rita Ionides | Regular Expressions]" />
  <link rel="stylesheet" href="../blog/style.css">
</head>

  <nav>
    <div class="title">Rita Ionides</div>
    <div class="links">
      <a href="../index.html">Home</a>
      <a href="../projects.html">Projects</a>
      <a href="../blog.html">Blog</a>
      <a href="../now.html">Now</a>
      <a href="../about.html">About</a>
      <a href="../cv.pdf" target="_blank">CV</a>
    </div>
  </nav>


<article class="prose lg:prose-xl mx-auto my-12 px-6">

    <h1 style="text-align: center;">Differential Privacy 101</h1>
    <h3 style="text-align: center;" ><em> Questions people ask at parties.</em></h3>

    <p style="text-indent:30px;">     Contrary to popular opinion, I do actually get asked about differential privacy at parties. (I go to some pretty nerdy parties, but the point stands). Iâ€™m also asked about it in coffee chats, in office hours by my curious students, and onceâ€”memorablyâ€”on a date, where I think the phrase â€œepsilon-ball around a databaseâ€ ended things prematurely.</p>

    <p style="text-indent:30px;">     In any case, itâ€™s come up enough that I thought it would be helpful to write up my favorite explanation of what differential privacy is, why it matters, and how it differs from other so-called privacy-preserving techniques. Weâ€™ll start with a story and a party game, and then for those who are interested in the actual implementation, Iâ€™ll share my take on the mathematical definitions. Theyâ€™re famously difficult to parse, but the right intuition helps a lot, and my goal with the story is to help you build that intuition.</p>

    <h3>Question #1: "Rita can you please explain your research like Iâ€™m 5."</h3>
    <p style="text-indent:30px;">     Differential privacy, at its bones, is a mathematical way to guarantee the safety of a piece of information in some kind of model. That model could be as simple as a median or as complex as an LLM or a diffusion modelâ€”the main thing that matters is that you canâ€™t tell what went in from anything that comes out.</p>

    <p style="text-indent:30px;">     This is obviously relevant in fields where we want to apply machine learning models to inherently sensitive data. I work with HIPAA-protected patient data for healthcare applications, where differential privacy is huge; other users include big tech companies and the US census. In practice, you make something differentially private by injecting noise somewhere in the model (more on that later!) â€“ thatâ€™s more or less the basics.</p>

    <h3>Question #2: "Iâ€™ve heard of things being 'privacy-preserving': how is differential privacy different?"</h3>
    <p>Hereâ€™s the example I like to give to my friends.</p>

    <p style="text-indent:30px;">     Say the United Nations creates a new disarmament initiative. Every country will secretly submit the true number of nuclear weapons they possess to a secure, incorruptible black-box machine. The machine then computes the arithmetic mean and reports it publicly. This seems fair, right? The mean here is a privacy-preserving method, meaning that it generally obscures private information.</p>

    <p style="text-indent:30px;">     This is a toy example, but the literature is full of â€˜privacy-preservingâ€™ methods: for example, two of the most popular are federated learning (which aggregates gradient updates instead of raw data) and privacy-preserving data synthesis (which generates synthetic data instead of using the real thing). These more complex models are serving the same purpose as our more humble mean.</p>

    <p style="text-indent:30px;">     Letâ€™s continue our example. In the peacekeeping initiative, every country contributes their number, and we learn that the mean is 42. But after a while, Russia decides to pull out of the agreement. They withdraw their data, and suddenly everyone can see that the mean has dropped to 33.</p>

    <p style="text-indent:30px;">     Yikes. You see the problem: even though the mean was anonymized, everyone knows exactly how many weapons Russia must have had. This is called a membership inference attack, and it is the problem with relying solely on â€œprivacy-preserving methods.â€ These methods tend to protect data in aggregate, but are often vulnerable to attacks that exploit subtle changesâ€”like adding or removing one person (or country). This is why we need differential privacy: it explicitly guards against this kind of inference. In fact, it formally ensures that the presence or absence of any single participant does not substantially affect the outcome.</p>

    <h3>Question #3: "This is where you start talking about math, yes?"</h3>
    <p style="text-indent:30px;">Yes!! Formally, a randomized algorithm A is said to be Îµ-differentially private if for any two neighboring datasets <em>D</em> and <em>D'</em> that differ by exactly one individual record (like the countries with and without Russia), and for any set of possible outputs S, we have:</p>
    <pre><code>    Pr[A(D) âˆˆ S] â‰¤ e^Îµ â‹… Pr[A(Dâ€²) âˆˆ S]</code></pre>
    <p style="text-indent:30px;">This means, broadly, that the probability that a particular result happens when your data is included is nearly the same as when it isn't. So whether or not youâ€™re in the dataset, the output wonâ€™t noticeably change.</p>

    <p style="text-indent:30px;">The parameter Îµ is often called the privacy budgetâ€”the lower it is, the more privacy youâ€™re guaranteed. Values like Îµ = 0.1 are very private, while Îµ = 5 means your data might have a significant effect on the output.</p>

    <h3>Question #4: "Is there a fun differentially private game I can play at home?"</h3>
    <p>Iâ€™m so glad you asked. Hereâ€™s one to try with a friend!</p>
    <h3>The Coin Toss Game</h3>
    <p><strong>You will need:</strong></p>
    <ul>
      <li>A friend</li>
      <li>A coin</li>
      <li>A secret</li>
    </ul>
    <p>Have your friend think of a secret (with a yes/no answer)â€”ideally something mildly scandalous. Did they eat your leftovers? Do they actually like your taste in music?</p>
    <p>Then have them follow these instructions:</p>
    <ol>
      <li>Flip a coin.</li>
      <li>If heads, answer truthfully.</li>
      <li>If tails, flip again:
        <ul>
          <li>If second coin is heads, answer â€œYes.â€</li>
          <li>If second coin is tails, answer â€œNo.â€</li>
        </ul>
      </li>
    </ol>
    <p>No matter what they say, you canâ€™t be sure whether theyâ€™re telling the truth. The randomness adds plausible deniability, and adding noise to obscure their datapoint is what differential privacy is all about.</p>

    <p>This game, in fact, turns out to be Îµ-differentially private for Îµ = ln(3). Here's why:</p>
    <ul>
      <li>If the true answer is â€œYes,â€ youâ€™ll respond â€œYesâ€ with probability 0.5 + 0.25 = 0.75</li>
      <li>If the true answer is â€œNo,â€ youâ€™ll respond â€œYesâ€ with probability 0.25</li>
    </ul>
    <p>So:</p>
    <pre><code>0.75 / 0.25 = 3 â‡’ Îµ = ln(3)</code></pre>
    <p>This bounded ratio is exactly what differential privacy asks for: no output is â€œtoo much more likelyâ€ depending on a single bit of private data.</p>

    <h3>Final thoughts</h3>
    <p>I know Iâ€™m biased, but differential privacy isnâ€™t just a research buzzword. Itâ€™s a deeply useful and beautiful idea, which formalizes something we all intuitively want: to be included in data science without being exposed by it. If I can help explain that at a party, in a blog post, or through a coin toss, Iâ€™ll consider my work worthwhile.</p>

    <p>Thanks for reading. Feel free to reach out if youâ€™d like to play the coin game sometimeâ€”I have plenty of secrets and a very reliable quarter.</p>
    <p><strong>Until next time,<br>- Rita</strong></p>

    <div class="share">
        <button onclick="navigator.clipboard.writeText(window.location.href)">ğŸ“ Share this article! </button>
      </div>

  </div>
</article>



<div container>
  <div id="mc_embed_shell">

    <div id="mc_embed_signup">
   <form action="https://github.us14.list-manage.com/subscribe/post?u=ac90916407742a29966588398&amp;id=9d2f0b6a5d&amp;f_id=00fbb5e5f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank">
      <div id="mc_embed_signup_scroll"><h2>Subscribe to the Regular Expressions Blog</h2>
          <div class="indicates-required"> All signal. No noise.</div>
          <div class="mc-field-group"><label for="mce-EMAIL">Email Address <span class="asterisk">*</span></label><input type="email" name="EMAIL" class="required email" id="mce-EMAIL" required="" value=""></div>
      <div id="mce-responses" class="clear foot">
          <div class="response" id="mce-error-response" style="display: none;"></div>
          <div class="response" id="mce-success-response" style="display: none;"></div>
      </div>
  <div aria-hidden="true" style="position: absolute; left: -5000px;">
      /* real people should not fill this in and expect good things - do not remove this or risk form bot signups */
      <input type="text" name="b_ac90916407742a29966588398_9d2f0b6a5d" tabindex="-1" value="">
  </div>
      <div class="optionalParent">
          <div class="clear foot">
              <input type="submit" name="subscribe" id="mc-embedded-subscribe" class="button" value="Subscribe">
              <p style="margin: 0px auto;"><a href="http://eepurl.com/jfq1JI" title="Mailchimp - email marketing made easy and fun"><span style="display: inline-block; background-color: transparent; border-radius: 4px;"><img class="refferal_badge" src="https://digitalasset.intuit.com/render/content/dam/intuit/mc-fe/en_us/images/intuit-mc-rewards-text-dark.svg" alt="Intuit Mailchimp" style="width: 220px; height: 40px; display: flex; padding: 2px 0px; justify-content: center; align-items: center;"></span></a></p>
          </div>
      </div>
  </div>
  </form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';fnames[6]='COMPANY';ftypes[6]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script></div>
</div>

</html>
